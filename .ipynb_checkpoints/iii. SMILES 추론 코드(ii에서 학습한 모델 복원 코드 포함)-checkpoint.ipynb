{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_JSGvkE0EW5"
   },
   "source": [
    "VM : Colab Pro(GPU)\n",
    "\n",
    "tensorflow :  2.2\n",
    "\n",
    "rdkit :  2020.03.3\n",
    "\n",
    "accelerator :  colab GPU(Tesla V100 16GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQDNdP58gXKt"
   },
   "source": [
    "## GPU 상태확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6420,
     "status": "ok",
     "timestamp": 1608153246500,
     "user": {
      "displayName": "김창헌",
      "photoUrl": "",
      "userId": "05733824982842229263"
     },
     "user_tz": -540
    },
    "id": "MR7qpu-TgWhL",
    "outputId": "d28206b0-419a-4422-83f6-f062bd2879c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 16 21:14:00 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwkGGPg3RIrI"
   },
   "source": [
    "## 구글 드라이브 연동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6764,
     "status": "ok",
     "timestamp": 1608153246866,
     "user": {
      "displayName": "김창헌",
      "photoUrl": "",
      "userId": "05733824982842229263"
     },
     "user_tz": -540
    },
    "id": "E9ja6eV7uUyn"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6749,
     "status": "ok",
     "timestamp": 1608153246867,
     "user": {
      "displayName": "김창헌",
      "photoUrl": "",
      "userId": "05733824982842229263"
     },
     "user_tz": -540
    },
    "id": "M3MK2d7OKXLT"
   },
   "outputs": [],
   "source": [
    "# !gsutil cp /content/gdrive/MyDrive/setup/Data/test.zip gs://smiles_all_under_70/to_predict_smiles/\n",
    "# !gsutil cp /content/gdrive/MyDrive/setup/Data/sample_submission.csv gs://smiles_all_under_70/to_predict_smiles/\n",
    "# !gsutil cp /content/gdrive/MyDrive/tokenizer_word36.pickle gs://smiles_all_under_70/to_predict_smiles/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxMhiU-Zl4Sq"
   },
   "source": [
    "# gcs에서 smiles 추론에 필요한 파일 가져오기\n",
    "  \n",
    "1.   tokenizer\n",
    "2.   model weights(encoder, decoder), \n",
    "3.   test.zip \n",
    "4. sample_submission.csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10953,
     "status": "ok",
     "timestamp": 1608153251132,
     "user": {
      "displayName": "김창헌",
      "photoUrl": "",
      "userId": "05733824982842229263"
     },
     "user_tz": -540
    },
    "id": "aOT8bfqiK-ZE",
    "outputId": "21563a64-9b9c-4e50-8f25-eef214e205e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://smiles_all_under_70/to_predict_smiles/sample_submission.csv...\n",
      "Copying gs://smiles_all_under_70/to_predict_smiles/test.zip...\n",
      "Copying gs://smiles_all_under_70/to_predict_smiles/tokenizer_word36.pickle...\n",
      "/ [3 files][216.1 MiB/216.1 MiB]                                                \n",
      "Operation completed over 3 objects/216.1 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r gs://smiles_all_under_70/to_predict_smiles ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16153,
     "status": "ok",
     "timestamp": 1608153256406,
     "user": {
      "displayName": "김창헌",
      "photoUrl": "",
      "userId": "05733824982842229263"
     },
     "user_tz": -540
    },
    "id": "KnLjdh1BE4Uu",
    "outputId": "849fbfa0-6974-4177-882a-fbc692e16ae1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://smiles_all_under_70/model/7_eff0_unfreeze_all_encoder_9300만.h5...\n",
      "/ [1 files][ 18.2 MiB/ 18.2 MiB]                                                \n",
      "Operation completed over 1 objects/18.2 MiB.                                     \n",
      "Copying gs://smiles_all_under_70/model/7_eff0_unfreeze_all_decoder_9300만.h5...\n",
      "- [1 files][ 34.3 MiB/ 34.3 MiB]                                                \n",
      "Operation completed over 1 objects/34.3 MiB.                                     \n",
      "Copying gs://smiles_all_under_70/model/7_val_loss_plot.txt...\n",
      "/ [1 files][  5.2 KiB/  5.2 KiB]                                                \n",
      "Operation completed over 1 objects/5.2 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r gs://smiles_all_under_70/model/7_eff0_unfreeze_all_encoder_9300만.h5 ./\n",
    "!gsutil cp -r gs://smiles_all_under_70/model/7_eff0_unfreeze_all_decoder_9300만.h5 ./\n",
    "!gsutil cp -r gs://smiles_all_under_70/model/7_val_loss_plot.txt ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXp82JAURLou"
   },
   "source": [
    "## 텐서플로우 2.2설치 (2.3은 불안정함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KAXIze1yEnZR"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow~=2.2.0 tensorflow_gcs_config~=2.2.0\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "niBKPsu8ROiB"
   },
   "source": [
    "## Rdkit 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0EtT_h2g30nb"
   },
   "outputs": [],
   "source": [
    "# rdkit 2020.03.3 버전 다운로드\n",
    "!pip install kora -q\n",
    "import kora.install.rdkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGXgxmpERXRg"
   },
   "source": [
    "## 필요 모듈 로드\n",
    "### rdkit, tensorflow, efficientNet, numpy 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6lgZW3Awboug"
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import RDConfig\n",
    "from rdkit import RDLogger\n",
    "from rdkit import rdBase\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "RDLogger.DisableLog('rdApp.*')  \n",
    "\n",
    "\n",
    "\n",
    "!pip install -q efficientnet >> /dev/null\n",
    "import efficientnet.tfkeras as efn\n",
    "import pandas as pd, numpy as np\n",
    "import tensorflow as tf, re, math\n",
    "import tensorflow.keras.backend as K\n",
    "import efficientnet.tfkeras as efn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import random, re, math\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf, tensorflow.keras.backend as K\n",
    "!pip install gcsfs #gcp 파일 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGYrSYLeF7QL"
   },
   "outputs": [],
   "source": [
    "# GCP PATH 설정\n",
    "#model save PATH설정\n",
    "base_path = 'gs://smiles_all_under_70/tfrecord_93517392_try2/'\n",
    "ROOT_PATH = f'./'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ju-f-13i3VGC"
   },
   "outputs": [],
   "source": [
    "# os.mkdir(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLTPT5RREzMj"
   },
   "outputs": [],
   "source": [
    "from tensorflow.data.experimental import AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQ00gXHIRdLW"
   },
   "source": [
    "### 각종 매개 변수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dkh01_mYXk6X"
   },
   "outputs": [],
   "source": [
    "units = 1024\n",
    "top_k = 36\n",
    "embedding_dim = 512\n",
    "vocab_size=top_k+1 # 패딩까지\n",
    "ef = 0\n",
    "dim = 224\n",
    "batch_size = 64*8\n",
    "batch_sizes = 64*8\n",
    "# seq_len = 72\n",
    "BATCH_SIZE=64*8; REPLICAS=8\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "EPOCHS = 50\n",
    "num_example = 93248512\n",
    "# EFF0\n",
    "feature_shape = 1280\n",
    "# attention\n",
    "attention_features_shape = 49"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scx69A4IS6uw"
   },
   "source": [
    "## 저장된 Tokenizer를 불러와서 숫자, 문자 매핑 딕셔너리 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lt38jIT3HpHA"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# with open('/content/gdrive/My Drive/tokenizer_word36.pickle', 'rb') as handle:\n",
    "with open('/content/to_predict_smiles/tokenizer_word36.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q7g-rzc7H9ww"
   },
   "outputs": [],
   "source": [
    "tar_to_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJN13PayrmvR"
   },
   "source": [
    "## 전이학습 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gItHqoyN-5o8"
   },
   "outputs": [],
   "source": [
    "EFNS = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, \n",
    "        efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6]\n",
    "\n",
    "\n",
    "class CNN_Encoder(tf.keras.Model): # tf.keras.Model을 상속받음.\n",
    "  # you should define your layers in __init__ \n",
    "  def __init__(self, embedding_dim):\n",
    "      super(CNN_Encoder, self).__init__() # super : 자식 클래스에서 부모클래스의 내용을 사용하고 싶을 경우 사용.\n",
    "      self.base = EFNS[ef](input_shape=(224,224,3),weights='imagenet',include_top=False) # --> (None,7,7,1280)\n",
    "      for i, layer in enumerate(self.base.layers): \n",
    "        layer.trainable = True\n",
    "      self.dropout = tf.keras.layers.Dropout(0.25)\n",
    "      self.fc = tf.keras.layers.Dense(embedding_dim, dtype='float32')\n",
    "\n",
    "  #you should implement the model's forward pass in call.\n",
    "  def call(self, x):\n",
    "      x = self.base(x)\n",
    "      x = self.dropout(x)\n",
    "      x = tf.reshape(x, [tf.shape(x)[0],tf.shape(x)[1]*tf.shape(x)[2],feature_shape]) # (BATCH_SIZE, 49,1280)\n",
    "      x = self.fc(x)\n",
    "      x = tf.nn.relu(x)\n",
    "\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2LTomG9L8Iha"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units) #units = 1024\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1) #Returns a tensor with a length 1 axis inserted at index axis.\n",
    "        \n",
    "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_JlELHOuqfj"
   },
   "outputs": [],
   "source": [
    "class RNN_Decoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, units, vocab_size):\n",
    "        super(RNN_Decoder, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim) #(37,512)\n",
    "        self.gru = tf.keras.layers.GRU(self.units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.dropout =tf.keras.layers.Dropout(0.25)\n",
    "        self.fc1 = tf.keras.layers.Dense(self.units)\n",
    "        self.fc2 = tf.keras.layers.Dense(vocab_size, dtype='float32')\n",
    "\n",
    "        self.attention = BahdanauAttention(self.units)\n",
    "\n",
    "    def call(self, x, features, hidden):\n",
    "        context_vector, attention_weights = self.attention(features, hidden)\n",
    "\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        x = self.fc1(output)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = tf.reshape(x, (-1, x.shape[2]))\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x, state, attention_weights\n",
    "    \n",
    "    def reset_state(self, batch_size):\n",
    "        return tf.zeros((batch_size, self.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pR7JT27Kvdp6"
   },
   "outputs": [],
   "source": [
    "encoder = CNN_Encoder(embedding_dim)\n",
    "decoder = RNN_Decoder(embedding_dim, units, vocab_size)\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "train_loss = tf.keras.metrics.Sum()\n",
    "valid_loss = tf.keras.metrics.Sum()\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "GJ6LOywTrjod"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgiViChqrzaB"
   },
   "source": [
    "# GCS 에 있는 tfrecords 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XSSoH8GQueI5"
   },
   "outputs": [],
   "source": [
    "\n",
    "# #gcp접근\n",
    "# from google.colab import auth, drive\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "QGxkMGBJHBUy"
   },
   "outputs": [],
   "source": [
    "train_tf_records = os.path.join(base_path, '*')\n",
    "train_data = np.sort(np.array(tf.io.gfile.glob(train_tf_records)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "coc0_xfu3uTN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gs://smiles_all_under_70/tfrecord_93517392_try2/batch_10005301'\n",
      " 'gs://smiles_all_under_70/tfrecord_93517392_try2/batch_10012469'\n",
      " 'gs://smiles_all_under_70/tfrecord_93517392_try2/batch_10019637' ...\n",
      " 'gs://smiles_all_under_70/tfrecord_93517392_try2/batch_9983797'\n",
      " 'gs://smiles_all_under_70/tfrecord_93517392_try2/batch_9990965'\n",
      " 'gs://smiles_all_under_70/tfrecord_93517392_try2/batch_9998133']\n",
      "13009\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uSzcqQYr2gF"
   },
   "source": [
    "## 0번쨰 폴더를 Holdout으로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XiIIJhr7IlgU"
   },
   "outputs": [],
   "source": [
    "\n",
    "kfold = KFold(n_splits=9000, shuffle=True, random_state=42)\n",
    "\n",
    "for i, (idx, vdx) in enumerate(kfold.split(train_data)):\n",
    "    if i == 0:\n",
    "      tr_data = train_data[idx]\n",
    "      val_data = train_data[vdx]\n",
    "      \n",
    "    else:\n",
    "      continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "b7MaWixgWjG5"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "sb67GE68WXh9"
   },
   "outputs": [],
   "source": [
    "tr_data = shuffle(tr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9t419to8I0gP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13007"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmtfvNb9r9sf"
   },
   "source": [
    "## tfrecords를 불러오는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "sBaLzSlH1xFE"
   },
   "outputs": [],
   "source": [
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.resize(image, [224,224])\n",
    "    return image\n",
    "\n",
    "def read_train_tfrecord(example):\n",
    "    features = {\n",
    "        'label': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_raw': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    \n",
    "\n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "    \n",
    "    data = decode_image(example['image_raw'])\n",
    "    label=example['label']\n",
    "    label = tf.io.decode_raw(label, out_type=tf.int32)\n",
    "    \n",
    "    return data, label\n",
    "\n",
    "def load_dataset(filenames, shuffle=False, repeat=False, aug=False):\n",
    "\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.cache()\n",
    "    \n",
    "    if repeat:\n",
    "        dataset = dataset.repeat()\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(BATCH_SIZE*2)\n",
    "        opt = tf.data.Options()\n",
    "        \n",
    "        opt.experimental_deterministic = False\n",
    "        dataset = dataset.with_options(opt)\n",
    "        \n",
    "    dataset = dataset.map(read_train_tfrecord, num_parallel_calls=AUTO)\n",
    "\n",
    "    # dataset = dataset.batch(BATCH_SIZE* REPLICAS)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_dataset = load_dataset(tr_data, shuffle=True, repeat=True)\n",
    "val_dataset = load_dataset(val_data, shuffle=False, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "eTUrLOVAyCpd"
   },
   "outputs": [],
   "source": [
    "# train_dist_ds = strategy.experimental_distribute_dataset(train_dataset)\n",
    "# valid_dist_ds = strategy.experimental_distribute_dataset(val_dataset)\n",
    "train_dist_ds = train_dataset\n",
    "valid_dist_ds = val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "kpcFZO6JDEjI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93248512"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "jTa9VgXTJa6i"
   },
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = int(num_example * 0.9998462602813437) // (BATCH_SIZE * 8)\n",
    "VAL_STEPS_PER_EPOCH = int(num_example * (1-0.9998462602813437)) // (BATCH_SIZE * 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "0AZYgtilvibR"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_fn(img_tensor, target, validation=False):\n",
    "    loss = 0\n",
    "    \n",
    "    hidden = decoder.reset_state(batch_size=target.shape[0])\n",
    "\n",
    "    dec_input = tf.expand_dims([tar_to_index['<']] * target.shape[0], 1)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        features = encoder(img_tensor)\n",
    "\n",
    "        for i in range(1, target.shape[1]):\n",
    "            predictions, hidden, _ = decoder(dec_input, features, hidden, training=True)\n",
    "\n",
    "            loss += loss_function(target[:, i], predictions)\n",
    "\n",
    "            dec_input = tf.expand_dims(target[:, i], 1)\n",
    "\n",
    "    trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "\n",
    "    total_loss = (loss / int(target.shape[1]))\n",
    "    train_loss.update_state(total_loss)\n",
    "    #return loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "VGhsjFa6ONuq"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def valid_step_fn(img_tensor, target):\n",
    "    loss = 0\n",
    "    hidden = decoder.reset_state(batch_size=target.shape[0])\n",
    "    dec_input = tf.expand_dims([tar_to_index['<']] * target.shape[0], 1)\n",
    "    features = encoder(img_tensor)\n",
    "\n",
    "    for i in range(1, target.shape[1]):\n",
    "        predictions, hidden, _ = decoder(dec_input, features, hidden, training=False)\n",
    "\n",
    "        loss += loss_function(target[:, i], predictions)\n",
    "\n",
    "        dec_input = tf.expand_dims(target[:, i], 1)\n",
    "\n",
    "    val_loss = (loss / int(target.shape[1]))\n",
    "    valid_loss.update_state(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "qcydzmqzax-t"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPwsyEuswq28"
   },
   "source": [
    "# load_weight를 실행하기 위해 모델을 building한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "dZA_cXen7AxL"
   },
   "outputs": [],
   "source": [
    "# encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "rZdqWGGP7CFH"
   },
   "outputs": [],
   "source": [
    "# decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LuQi8Ni4pg_Z"
   },
   "outputs": [],
   "source": [
    "# train_loss.reset_states()\n",
    "# valid_loss.reset_states()\n",
    "for (batch, (img_tensor, target)) in enumerate(train_dist_ds):\n",
    "  valid_step_fn(img_tensor,target)\n",
    "  # strategy.run(train_step_fn, args=(img_tensor, target))\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6D_ESXW5phft"
   },
   "source": [
    "# 학습시킨 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQyZB4NRGOO-"
   },
   "outputs": [],
   "source": [
    "# /content/model/eff0_unfreeze_all_encoder_9300만.h5\n",
    "# /content/model/eff0_fold0_molecule_decoder_9300만.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fBt51tOo3saj"
   },
   "outputs": [],
   "source": [
    "encoder.load_weights(os.path.join(ROOT_PATH, \"7_eff0_unfreeze_all_encoder_9300만.h5\"))\n",
    "decoder.load_weights(os.path.join(ROOT_PATH, \"7_eff0_unfreeze_all_decoder_9300만.h5\"))\n",
    "# encoder.load_weights('/content/to_predict_smiles/eff0_fold0_molecule_encoder_1000만.h5')\n",
    "# decoder.load_weights('/content/to_predict_smiles/eff0_fold0_molecule_decoder_1000만.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyoobJ9p6wEg"
   },
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIci8x3M676X"
   },
   "outputs": [],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gdwf61MrMf9v"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "max_length = 72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkrDrXDDB_Hf"
   },
   "source": [
    "# 테스트셋 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdPRBJBW0EZ8"
   },
   "source": [
    "### 문자를 숫자에 매핑하는 딕셔너리를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coSfcR7aGvjB"
   },
   "outputs": [],
   "source": [
    "index_to_tar = {v:k for k, v in tar_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XmZpISZ-5-bM"
   },
   "outputs": [],
   "source": [
    "index_to_tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9r5W2tW0EaH"
   },
   "source": [
    "### Gcs로부터 다운받은 테스트 이미지파일을 압축해제합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-XJeAMOqfjb"
   },
   "outputs": [],
   "source": [
    "!unzip /content/to_predict_smiles/test.zip -d ./test/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-KwsnwR0EaM"
   },
   "source": [
    "### predict함수와  pred_함수 정의\n",
    "\n",
    "    1. predict함수는 valid_step_fn함수와 내부 과정이 거의 유사합니다.\n",
    "    \n",
    "    - 차이점은 valid_step_fn은 prediction과 target사이의 loss를 구했지만, predict는  prediction값을 np.argmax를 이용해서 문자로 매핑할수있는 숫자로 변환한다는 것입니다.\n",
    "\n",
    "    - 또 한가지 차이점은 학습과 검정시에는 teacher forcing이 적용되어 dec_input을 실제 target값으로 주었지만 테스트셋 예측시에는 예측한 predictions값을 dec_input으로 설정해줍니다.\n",
    "\n",
    "\n",
    "    2. pred_함수는 predict함수와 다르게 예측시에 argmax가 아닌 tf.random.categorical를 사용합니다. tf.random.categorical을 사용하면 범주형 분포에 맞게 1개를 추출하므로 최대값의 index가 아닌 확률적으로 다른 index를 결과로 얻을 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SkIA6LN6kaHj"
   },
   "outputs": [],
   "source": [
    "# 가장 높은 확률로 예측\n",
    "def predict(img_tensor):\n",
    "    batch_features = img_tensor    \n",
    "    hidden = decoder.reset_state(batch_size=img_tensor.shape[0])\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<']] * img_tensor.shape[0], 1)\n",
    "    features = encoder(batch_features)\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        predictions, hidden, _ = decoder(dec_input, features, hidden)\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        result.append(predictions)\n",
    "        dec_input = tf.expand_dims(predictions, 1)\n",
    "    \n",
    "    return np.array(result)\n",
    "\n",
    "# 비교적 높은 확률들로 예측\n",
    "def predict_(img_tensor):\n",
    "    batch_features = img_tensor    \n",
    "    hidden = decoder.reset_state(batch_size=img_tensor.shape[0])\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<']] * img_tensor.shape[0], 1)\n",
    "    features = encoder(batch_features)\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        predictions, hidden, _ = decoder(dec_input, features, hidden)\n",
    "        predictions = tf.random.categorical(predictions, 1)[:, 0].numpy()\n",
    "        result.append(predictions)\n",
    "        dec_input = tf.expand_dims(predictions, 1)\n",
    "    \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DhbpBNU0EaS"
   },
   "source": [
    "### sample_submission파일을 불러와서 예측할 테스트이미지 파일 경로가 담긴 test_img_path 리스트를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpaBayKRkmJ3"
   },
   "outputs": [],
   "source": [
    "TEST_PATH = '/content/test/'\n",
    "with open('/content/to_predict_smiles/sample_submission.csv', 'r') as csv_file:\n",
    "    data = csv_file.read()\n",
    "    \n",
    "test_img_path = []\n",
    "for line in data.split('\\n')[1:-1]:\n",
    "    image_id, smiles = line.split(',')\n",
    "    full_image_path = TEST_PATH + image_id\n",
    "\n",
    "    test_img_path.append(full_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pARYxYkxkqEi"
   },
   "outputs": [],
   "source": [
    "def decode_image(image_data):\n",
    "    image = open(image_data, 'rb').read()\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.resize(image, [224,224])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHojsNzx0EaZ"
   },
   "source": [
    "## dataset_test생성\n",
    "\n",
    "tf.data는 데이터 feeding용 모듈로써 배치사이즈 설정 및 shuffle기능 등을 제공하여 Dataset, TFRecordDataset등 하위 모듈들을 제공합니다. 학습시에는 TFRecordDatase을 사용했지만 테스트이미지는 tfrecord형태가 아니므로 Dataset을 사용하도록 하겠습니다.\n",
    "\n",
    "    1. tf.data.Dataset.from_tensor_slices 을 이용해서 test_img_path로부터 dataset_test를 만듭니다. \n",
    "    \n",
    "    2. map을 이용하여 후처리작업을 실시합니다. map을 위한 함수인 decode_image는 테스트이미지를 바이너리 형식으로 읽어들인 후 학습한 모델의 입력 형식에 맞게 변환하는 함수입니다.\n",
    "    \n",
    "    3. batch와, prefetch를 적용합니다. tf.data.experimental.AUTOTUNE으로 설정하면 tf.data런타임이 실행시에 동적으로 값을 조정하도록 만듭니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juBkR940krcF"
   },
   "outputs": [],
   "source": [
    "dataset_test = tf.data.Dataset.from_tensor_slices((test_img_path))\n",
    "dataset_test = dataset_test.map(lambda item1: tf.numpy_function(decode_image, [item1], [tf.float32]), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset_test = dataset_test.batch(BATCH_SIZE)\n",
    "dataset_test = dataset_test.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)#현재 element가 처리 되는 동안 이후 element를 준비합니다 추가 메모리를 사용하는 대신 대기 시간이 줄어들고 처리량이 향상됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFIOAO_Z0Ead"
   },
   "source": [
    "batch단위로 예측을 실시하여 test_result에 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "749ZuPnqktXa"
   },
   "outputs": [],
   "source": [
    "test_result = []\n",
    "for batch in tqdm(dataset_test, position=0, leave=True): #Solution working in Google Colab to avoid printing to a newline\n",
    "    test_result.extend(predict(batch[0]).T) # extend는 iterable의 각 항목들을 넣습니다\n",
    "test_result = np.array(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1xZp_0U0Eai"
   },
   "source": [
    "예측 결과를 smiles로 변환합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFSFq7OLkx4q"
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for rid in range(len(test_img_path)):\n",
    "    pred = ''.join([tokenizer.index_word[i] for i in test_result[rid]])\n",
    "    pred = pred.split('>')[0]\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blsbeXkm0Eam"
   },
   "source": [
    "rdkit을 이용하여 예측 결과가 SMILES규칙에 맞는지 검사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoTBXKL-kyqP"
   },
   "outputs": [],
   "source": [
    "error_idx = []\n",
    "for i, pred in enumerate(preds):\n",
    "    m = Chem.MolFromSmiles(pred)\n",
    "    if m == None:\n",
    "        error_idx.append(i)\n",
    "error_idx = np.array(error_idx)\n",
    "error_idx_ = error_idx.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleVjBMm3aEm"
   },
   "outputs": [],
   "source": [
    "error_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FvNLgISk3Uy1"
   },
   "outputs": [],
   "source": [
    "len(error_idx_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYC-KwSK0Eaw"
   },
   "source": [
    "SMILES 규칙에 맞지 않는 데이터는 확률이 높은 다른값들로 다시 예측합니다.\n",
    "\n",
    "대부분의 결과가 SMILES 규칙에 맞게 예측할 때까지 반복합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tn2pj3aYk067"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "drop_error = []\n",
    "while True:\n",
    "    error_idx_dict = {}\n",
    "    for i, e in enumerate(error_idx_):\n",
    "        error_idx_dict[i] = e\n",
    "        \n",
    "    img_name_test_ = np.array(test_img_path)[error_idx_]\n",
    "    dataset_test_ = tf.data.Dataset.from_tensor_slices((img_name_test_))\n",
    "    dataset_test_ = dataset_test_.map(lambda item1: tf.numpy_function(decode_image, [item1], [tf.float32]), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset_test_ = dataset_test_.batch(BATCH_SIZE)\n",
    "    dataset_test_ = dataset_test_.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    test_result_ = []\n",
    "    for batch in dataset_test_:\n",
    "        test_result_.extend(predict_(batch[0]).T)\n",
    "    test_result_ = np.array(test_result_)\n",
    "\n",
    "    preds_ = []\n",
    "    for rid in range(test_result_.shape[0]):\n",
    "        pred = ''.join([tokenizer.index_word[i] for i in test_result_[rid] if i not in [0]])\n",
    "        pred = pred.split('>')[0]\n",
    "        preds_.append(pred)\n",
    "    \n",
    "    for i, pred in enumerate(preds_):\n",
    "        m = Chem.MolFromSmiles(pred)\n",
    "        if m != None:\n",
    "            preds[error_idx_dict[i]] = pred\n",
    "            drop_idx = np.where(error_idx==error_idx_dict[i])[0]\n",
    "            drop_error.append(drop_idx[0])\n",
    "    error_idx_ = np.delete(error_idx, drop_error)\n",
    "    clear_output(wait=True)\n",
    "    print(len(list(drop_error)), '/', error_idx.shape[0])\n",
    "    \n",
    "    if error_idx.shape[0]-len(list(drop_error)) < 10 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBg6zQuAcxDq"
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqXLpVD30Ea0"
   },
   "outputs": [],
   "source": [
    "# 예측결과를 제출형식에 맞춰 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E5mJ7h9UqxYN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# submission = pd.read_csv('/content/gdrive/My Drive/setup/Data/sample_submission.csv')\n",
    "submission = pd.read_csv('/content/to_predict_smiles/sample_submission.csv')\n",
    "submission['SMILES'] = np.array(preds)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ARw_UkW4cda"
   },
   "source": [
    "# 참고문헌\n",
    "\n",
    "참고 코드 :\n",
    "\n",
    "https://dacon.io/competitions/official/235640/codeshare/1703?page=1&dtype=recent&ptype=pub\n",
    "https://dacon.io/competitions/official/235640/codeshare/1644?page=1&dtype=recent&ptype=pub\n",
    "    \n",
    "설명 참고사이트 :   \n",
    "https://hcnoh.github.io/2018-11-05-tensorflow-data-module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "iii. re7_SMILES 추론 코드.ipynb",
   "provenance": [
    {
     "file_id": "1H_Bm8VL_zk5raX0Nns-sIVPwk2Xg1ePH",
     "timestamp": 1607399156184
    },
    {
     "file_id": "1ASJ14GVrB1vhT0EOfHguJj2UUuloolrP",
     "timestamp": 1607162155691
    },
    {
     "file_id": "1giw-KM4_uFGnpBi2WhKx87LcMgvkaNe8",
     "timestamp": 1606898519262
    },
    {
     "file_id": "1h-B6JP08Eh39jsaZhPWqg2cqVTw0e0hW",
     "timestamp": 1606898264089
    }
   ],
   "toc_visible": true,
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
